{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9O8VOTiShbZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AppimateSA/AutoVisual/blob/text2video_stablediffusion/notebooks/Text-To-Video-Finetuning.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FPL6HGLShbb"
      },
      "source": [
        "# Prepare the enviornment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl9M30V4Shbb",
        "outputId": "7082a1d8-031f-4e39-bd79-b66ffae3b49a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    WORKING_DIR = '.'\n",
        "    IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "    WORKING_DIR = '/content'\n",
        "    drive.mount('/content/drive',  force_remount=True) # Mount drive in order access Google drive\n",
        "if IN_COLAB:\n",
        "    sys.path.insert(0, WORKING_DIR)\n",
        "else:\n",
        "    # The actual code is one level higher in folder depth/structure, so we're elevating this notebook.\n",
        "    sys.path.insert(0,f\"{WORKING_DIR}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1412IyZUKUJ"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GdqePw3Shbc"
      },
      "source": [
        "### Install Main Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # %cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/\n",
        "# %cd WORKING_DIR\n",
        "\n",
        "# dataFolder = os.path.expanduser('~/.cache/models')\n",
        "dataFolder = os.path.expanduser('~/Desktop/AutoVisual')\n",
        "# %cd {dataFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkZn2d3-UbFM"
      },
      "source": [
        "### Install Main Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5cN5AOw_Yf3",
        "outputId": "debd8a8f-6cc9-481b-f642-a2ae63b8dedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated Git hooks.\n",
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "# !git clone https://huggingface.co/damo-vilab/text-to-video-ms-1.7b ./models/model_scope_diffusers/\n",
        "# # %cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awu5Sjm7LFqc"
      },
      "source": [
        "## Preprocess Videos\n",
        "See arguments you can pass [here](https://github.com/ExponentialML/Video-BLIP2-Preprocessor#default-arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFdu2IK6BZcj",
        "outputId": "11ece480-8cab-43c9-e691-c9e052ceeb59"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    dataFolder = f'{WORKING_DIR}/drive/MyDrive/Colab Notebooks/datasets/Appimate'\n",
        "else:\n",
        "    dataFolder = os.path.expanduser( '~/.cache/datasets/Appimate' )\n",
        "    \n",
        "# print(dataFolder)\n",
        "# !pwd\n",
        "# # %cd {WORKING_DIR}/AutoVisual\n",
        "# !python preprocess.py \\\n",
        "#     --input_dir '{dataFolder}' \\\n",
        "#     --json_file_path '{dataFolder}/dataset.json' \\\n",
        "#     --skip_interval 1 \\\n",
        "#     --output_dir '{dataFolder}/T2V'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4dk_Mnajp4"
      },
      "source": [
        "## Train Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKG_b7qua7SX",
        "outputId": "7ab65872-74b7-4a37-8b35-8817ba3802be"
      },
      "outputs": [],
      "source": [
        "# %%writefile ./configs/my_config_hq.yaml\n",
        "\n",
        "# pretrained_model_path: \"/content/text-to-video-ms-1.7b\" #https://huggingface.co/damo-vilab/text-to-video-ms-1.7b/tree/main\n",
        "# output_dir: \"/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/AutoVisual/outputs\"\n",
        "# train_text_encoder: False\n",
        "# #resume_from_checkpoint: None\n",
        "# dataset_types:\n",
        "#   - 'folder'\n",
        "\n",
        "# train_data:\n",
        "#   path: \"/content/train_all_mp4\"\n",
        "#   preprocessed: True\n",
        "#   n_sample_frames: 2\n",
        "#   shuffle_frames: False\n",
        "#   width: 128 #384\n",
        "#   height: 128 #256\n",
        "#   sample_start_idx: 0\n",
        "#   sample_frame_rate: 24\n",
        "#   vid_data_key: \"video_path\"\n",
        "\n",
        "#   # single_video_path: \"\"\n",
        "#   single_video_prompt: \"\"\n",
        "\n",
        "# validation_data:\n",
        "#   prompt: \"\"\n",
        "#   sample_preview: True\n",
        "#   num_frames: 16\n",
        "#   width: 128 #384\n",
        "#   height: 128 #256\n",
        "#   num_inference_steps: 50\n",
        "#   guidance_scale: 9\n",
        "\n",
        "# learning_rate: 1e-5\n",
        "# adam_weight_decay: 1e-2\n",
        "# train_batch_size: 1\n",
        "# max_train_steps: 50000\n",
        "# checkpointing_steps: 2500\n",
        "# validation_steps: 2500\n",
        "# trainable_modules:\n",
        "#   - \"attentions\"\n",
        "# seed: 64\n",
        "# mixed_precision: \"fp16\"\n",
        "# use_8bit_adam: False # This seems to be incompatible at the moment.\n",
        "\n",
        "# gradient_checkpointing: True\n",
        "# text_encoder_gradient_checkpointing: True\n",
        "# # Xformers must be installed\n",
        "# enable_xformers_memory_efficient_attention: False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1eFvYTLldG",
        "outputId": "c827cf29-a327-410d-cc66-0741fbc7047c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/luthando/miniconda3/envs/vgen/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.2.0+cu121 with CUDA 1201 (you have 2.2.0)\n",
            "    Python  3.8.18 (you have 3.8.18)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "Initializing the conversion map\n",
            "03/27/2024 13:12:35 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cpu\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "/home/luthando/miniconda3/envs/vgen/lib/python3.8/site-packages/diffusers/configuration_utils.py:217: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
            "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "{'variance_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "{'downsample_padding', 'mid_block_scale_factor'} was not found in config. Values will be initialized to default values.\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 1032, in <module>\n",
            "    main(**config)\n",
            "  File \"train.py\", line 557, in main\n",
            "    noise_scheduler, tokenizer, text_encoder, vae, unet = load_primary_models(pretrained_model_path)\n",
            "  File \"train.py\", line 129, in load_primary_models\n",
            "    unet = UNet3DConditionModel.from_pretrained(pretrained_model_path, subfolder=\"unet\")\n",
            "  File \"/home/luthando/miniconda3/envs/vgen/lib/python3.8/site-packages/diffusers/models/modeling_utils.py\", line 604, in from_pretrained\n",
            "    raise ValueError(\n",
            "ValueError: Cannot load <class 'models.unet_3d_condition.UNet3DConditionModel'> from /home/luthando/Desktop/text2video_finetuning/models/model_scope_diffusers/text-to-video-ms-1.7b because the following keys are missing: \n",
            " up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.downsamplers.0.conv.weight, down_blocks.0.temp_convs.0.conv3.0.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.0.proj_in.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.0.proj_in.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.resnets.0.conv_shortcut.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias, up_blocks.3.resnets.1.norm1.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.3.temp_convs.0.conv2.0.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn1.to_v.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.3.temp_attentions.0.proj_in.weight, mid_block.temp_attentions.0.transformer_blocks.0.norm2.bias, up_blocks.0.resnets.1.norm1.bias, up_blocks.1.resnets.1.conv1.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.resnets.0.norm1.bias, up_blocks.0.temp_convs.1.conv4.0.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight, mid_block.resnets.0.norm1.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.resnets.2.conv1.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, mid_block.temp_convs.1.conv4.0.weight, down_blocks.2.temp_convs.1.conv1.2.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.2.temp_convs.1.conv4.3.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm1.bias, down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.3.resnets.0.conv1.bias, up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.2.temp_convs.2.conv4.0.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm3.weight, up_blocks.1.attentions.1.proj_out.bias, up_blocks.2.temp_convs.2.conv1.0.bias, down_blocks.1.resnets.0.conv2.bias, up_blocks.0.resnets.0.conv_shortcut.weight, up_blocks.3.temp_convs.0.conv2.0.bias, up_blocks.3.temp_attentions.0.proj_in.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.resnets.1.time_emb_proj.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm1.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, mid_block.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, mid_block.attentions.0.norm.weight, mid_block.resnets.0.conv1.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm3.bias, up_blocks.0.resnets.1.conv2.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.temp_convs.1.conv1.2.bias, transformer_in.transformer_blocks.0.norm2.bias, up_blocks.1.temp_convs.0.conv4.3.bias, up_blocks.0.resnets.2.conv2.weight, up_blocks.0.temp_convs.0.conv4.0.bias, down_blocks.3.temp_convs.0.conv3.0.bias, up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.3.temp_convs.0.conv1.2.bias, down_blocks.1.temp_convs.1.conv1.2.weight, up_blocks.0.resnets.1.time_emb_proj.weight, up_blocks.2.temp_convs.1.conv1.0.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm3.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.0.resnets.1.conv1.bias, up_blocks.2.temp_attentions.1.proj_out.bias, transformer_in.transformer_blocks.0.attn1.to_q.weight, down_blocks.1.temp_convs.0.conv3.0.bias, down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias, down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias, up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.1.temp_convs.2.conv1.2.bias, down_blocks.0.temp_convs.0.conv2.3.weight, up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.1.resnets.1.conv_shortcut.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.temp_convs.0.conv4.0.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.0.resnets.0.norm2.weight, up_blocks.2.temp_attentions.1.proj_out.weight, up_blocks.0.resnets.1.norm1.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, mid_block.resnets.1.norm2.weight, up_blocks.2.resnets.1.conv_shortcut.weight, up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias, conv_in.bias, mid_block.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm2.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.1.resnets.1.norm1.bias, up_blocks.3.temp_convs.1.conv2.0.bias, up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.2.resnets.0.conv2.bias, down_blocks.1.temp_convs.1.conv2.0.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.resnets.1.time_emb_proj.weight, up_blocks.1.resnets.2.conv2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.resnets.0.norm2.weight, up_blocks.1.attentions.1.norm.weight, down_blocks.2.temp_convs.1.conv3.0.bias, up_blocks.2.temp_attentions.2.norm.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.3.resnets.2.conv_shortcut.weight, up_blocks.0.resnets.1.time_emb_proj.bias, mid_block.temp_attentions.0.norm.weight, up_blocks.0.resnets.2.norm1.bias, down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.0.temp_convs.2.conv2.0.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.3.resnets.2.conv2.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm1.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.weight, up_blocks.0.resnets.0.conv1.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.temp_attentions.2.proj_in.bias, up_blocks.1.temp_attentions.1.proj_out.bias, up_blocks.3.attentions.1.transformer_blocks.0.norm3.bias, down_blocks.0.resnets.1.norm1.bias, up_blocks.0.temp_convs.1.conv2.0.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.2.resnets.0.conv2.bias, mid_block.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.temp_convs.0.conv2.3.bias, down_blocks.0.temp_convs.1.conv4.0.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.3.resnets.1.conv1.weight, up_blocks.3.attentions.0.norm.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm3.bias, mid_block.attentions.0.proj_in.bias, down_blocks.3.temp_convs.0.conv4.3.bias, down_blocks.3.resnets.0.norm1.weight, down_blocks.3.temp_convs.0.conv4.3.weight, down_blocks.1.temp_convs.1.conv4.3.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, mid_block.temp_attentions.0.proj_out.weight, up_blocks.2.temp_attentions.0.proj_out.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, mid_block.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.1.temp_attentions.0.norm.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm3.weight, up_blocks.1.temp_convs.0.conv1.2.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight, mid_block.temp_convs.0.conv1.2.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.3.temp_convs.0.conv3.3.bias, up_blocks.3.temp_convs.0.conv1.2.weight, up_blocks.1.temp_attentions.1.proj_in.bias, up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.1.temp_convs.0.conv4.0.bias, down_blocks.3.resnets.0.time_emb_proj.weight, up_blocks.1.temp_convs.1.conv1.2.bias, up_blocks.2.temp_convs.0.conv3.0.bias, up_blocks.3.temp_convs.1.conv4.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.0.temp_convs.1.conv4.3.weight, down_blocks.1.temp_convs.0.conv4.3.weight, up_blocks.2.temp_attentions.1.norm.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, down_blocks.0.temp_attentions.0.proj_out.weight, down_blocks.1.resnets.0.conv_shortcut.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.0.resnets.1.conv1.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.resnets.1.time_emb_proj.bias, down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.3.temp_convs.2.conv1.2.weight, up_blocks.1.resnets.2.norm2.bias, down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm2.weight, up_blocks.2.temp_convs.0.conv1.2.bias, down_blocks.0.temp_convs.1.conv1.2.weight, mid_block.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm1.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.3.attentions.1.norm.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.resnets.1.time_emb_proj.weight, up_blocks.1.temp_convs.1.conv2.3.weight, down_blocks.2.attentions.1.proj_in.weight, down_blocks.1.temp_convs.0.conv3.3.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.2.resnets.1.time_emb_proj.bias, down_blocks.0.attentions.1.proj_in.weight, mid_block.temp_attentions.0.transformer_blocks.0.norm3.weight, up_blocks.3.temp_convs.0.conv1.0.weight, up_blocks.2.upsamplers.0.conv.bias, down_blocks.1.downsamplers.0.conv.bias, up_blocks.2.temp_attentions.1.proj_in.weight, up_blocks.1.temp_convs.1.conv3.3.weight, down_blocks.0.resnets.0.conv1.bias, down_blocks.2.temp_convs.1.conv1.2.weight, up_blocks.3.attentions.0.proj_out.weight, mid_block.temp_convs.1.conv2.0.bias, up_blocks.3.temp_convs.2.conv3.0.bias, down_blocks.2.resnets.0.time_emb_proj.bias, down_blocks.2.temp_attentions.0.norm.weight, down_blocks.0.attentions.1.proj_in.bias, up_blocks.1.resnets.0.conv2.bias, up_blocks.1.resnets.1.norm2.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.3.attentions.2.transformer_blocks.0.norm1.bias, down_blocks.3.resnets.0.time_emb_proj.bias, down_blocks.1.resnets.1.time_emb_proj.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.upsamplers.0.conv.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm3.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.resnets.0.conv1.weight, mid_block.resnets.0.norm2.bias, up_blocks.2.attentions.1.transformer_blocks.0.norm3.weight, up_blocks.1.temp_convs.2.conv2.3.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.2.resnets.2.conv1.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm2.bias, up_blocks.2.attentions.1.transformer_blocks.0.norm1.bias, mid_block.attentions.0.proj_out.weight, up_blocks.2.temp_convs.2.conv3.0.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.2.norm.bias, down_blocks.0.temp_convs.0.conv3.3.bias, up_blocks.3.resnets.0.conv1.bias, up_blocks.1.temp_convs.1.conv1.0.weight, up_blocks.1.attentions.0.proj_out.weight, down_blocks.1.temp_attentions.1.norm.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.2.transformer_blocks.0.norm1.weight, up_blocks.1.resnets.1.norm2.weight, down_blocks.2.temp_convs.0.conv1.2.weight, up_blocks.2.temp_convs.1.conv3.3.bias, down_blocks.1.resnets.1.norm1.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn1.to_q.weight, mid_block.resnets.1.norm2.bias, up_blocks.1.temp_convs.0.conv1.0.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm2.bias, up_blocks.2.temp_convs.1.conv2.3.bias, transformer_in.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.2.temp_convs.1.conv1.0.bias, down_blocks.0.temp_convs.0.conv4.3.bias, up_blocks.1.temp_convs.1.conv3.0.weight, down_blocks.2.resnets.1.conv1.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, down_blocks.1.attentions.0.proj_out.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.3.temp_convs.0.conv2.3.weight, down_blocks.2.resnets.1.norm2.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_q.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.0.temp_convs.0.conv1.2.weight, up_blocks.1.temp_convs.1.conv4.0.weight, up_blocks.1.temp_convs.2.conv4.0.weight, up_blocks.2.resnets.1.norm1.weight, up_blocks.2.attentions.2.proj_in.weight, down_blocks.1.resnets.0.conv_shortcut.bias, mid_block.temp_attentions.0.transformer_blocks.0.norm1.bias, transformer_in.proj_out.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.resnets.2.norm1.bias, mid_block.temp_convs.0.conv4.0.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm2.weight, up_blocks.3.temp_attentions.1.proj_in.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.resnets.0.conv2.weight, up_blocks.1.resnets.1.conv1.weight, up_blocks.2.temp_attentions.0.norm.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm2.weight, down_blocks.0.attentions.1.proj_out.bias, mid_block.resnets.0.conv1.weight, up_blocks.1.temp_attentions.0.proj_out.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.1.resnets.1.conv1.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_q.weight, down_blocks.1.resnets.1.time_emb_proj.bias, down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.resnets.1.norm2.weight, down_blocks.3.temp_convs.1.conv3.3.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm1.weight, up_blocks.3.temp_attentions.1.proj_out.weight, down_blocks.0.attentions.0.norm.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.2.proj_in.bias, up_blocks.1.resnets.2.norm1.weight, time_embedding.linear_1.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight, up_blocks.0.temp_convs.1.conv1.2.bias, up_blocks.0.temp_convs.0.conv3.0.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn2.to_v.weight, down_blocks.2.temp_convs.0.conv3.0.bias, up_blocks.2.resnets.0.norm1.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.2.temp_attentions.2.proj_in.weight, transformer_in.norm.bias, mid_block.resnets.1.time_emb_proj.weight, down_blocks.1.attentions.0.proj_in.bias, up_blocks.3.resnets.1.norm2.weight, up_blocks.3.temp_convs.1.conv2.0.weight, up_blocks.2.temp_attentions.2.norm.bias, up_blocks.3.temp_attentions.2.norm.weight, down_blocks.1.resnets.1.norm2.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm2.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.attentions.0.proj_out.weight, up_blocks.2.temp_attentions.2.proj_out.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn1.to_k.weight, up_blocks.2.resnets.2.norm1.bias, up_blocks.0.temp_convs.1.conv2.3.weight, down_blocks.3.resnets.1.norm1.weight, up_blocks.2.resnets.2.norm2.bias, up_blocks.3.temp_convs.1.conv1.0.weight, up_blocks.2.temp_convs.2.conv2.3.weight, down_blocks.3.temp_convs.1.conv2.3.bias, mid_block.temp_convs.1.conv3.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight, up_blocks.3.resnets.0.time_emb_proj.bias, up_blocks.3.temp_convs.0.conv3.3.bias, down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.temp_convs.1.conv2.0.weight, up_blocks.3.temp_convs.2.conv2.0.weight, up_blocks.2.temp_convs.2.conv2.0.bias, down_blocks.1.temp_convs.1.conv2.3.bias, down_blocks.3.temp_convs.1.conv1.0.weight, mid_block.resnets.1.conv1.bias, up_blocks.1.temp_convs.2.conv2.0.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.temp_convs.0.conv2.3.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.0.temp_convs.0.conv2.0.bias, up_blocks.1.resnets.1.time_emb_proj.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm1.bias, up_blocks.2.temp_convs.1.conv4.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias, transformer_in.transformer_blocks.0.norm3.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.temp_convs.1.conv1.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight, up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.resnets.0.conv1.weight, mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.2.temp_convs.1.conv1.0.weight, up_blocks.0.temp_convs.1.conv2.3.bias, down_blocks.0.temp_attentions.1.proj_out.bias, down_blocks.0.attentions.0.norm.weight, mid_block.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.0.temp_attentions.0.norm.bias, up_blocks.2.temp_convs.2.conv3.3.bias, down_blocks.3.temp_convs.0.conv2.0.bias, down_blocks.3.temp_convs.0.conv1.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.0.resnets.0.norm1.weight, down_blocks.0.temp_convs.1.conv2.0.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight, transformer_in.proj_out.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight, mid_block.resnets.0.time_emb_proj.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.temp_attentions.0.proj_out.bias, up_blocks.2.temp_convs.0.conv4.3.weight, up_blocks.2.attentions.1.transformer_blocks.0.norm3.bias, up_blocks.3.temp_convs.1.conv4.3.weight, up_blocks.0.upsamplers.0.conv.bias, up_blocks.2.attentions.2.norm.weight, down_blocks.3.temp_convs.1.conv2.3.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, transformer_in.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.0.proj_in.bias, up_blocks.0.resnets.2.conv1.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.2.temp_convs.0.conv2.3.weight, down_blocks.0.resnets.0.conv2.weight, up_blocks.1.attentions.1.norm.bias, down_blocks.0.attentions.1.proj_out.weight, down_blocks.2.temp_attentions.1.norm.bias, transformer_in.transformer_blocks.0.attn1.to_out.0.bias, mid_block.temp_convs.1.conv1.0.bias, down_blocks.2.temp_convs.0.conv3.3.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn2.to_v.weight, mid_block.resnets.0.conv2.weight, down_blocks.3.resnets.0.norm2.bias, down_blocks.2.resnets.0.norm2.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.temp_convs.2.conv4.3.bias, up_blocks.2.temp_convs.0.conv2.0.weight, down_blocks.3.temp_convs.1.conv4.3.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.1.temp_attentions.0.proj_in.bias, up_blocks.1.temp_convs.0.conv3.0.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn1.to_q.weight, up_blocks.0.upsamplers.0.conv.weight, down_blocks.3.temp_convs.0.conv1.0.bias, up_blocks.2.temp_attentions.2.proj_out.weight, up_blocks.0.temp_convs.2.conv3.0.weight, down_blocks.2.resnets.0.norm2.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn1.to_q.weight, down_blocks.3.temp_convs.1.conv1.2.weight, up_blocks.3.temp_convs.2.conv3.3.weight, mid_block.temp_convs.0.conv1.0.bias, up_blocks.2.temp_convs.2.conv2.0.weight, down_blocks.0.temp_convs.0.conv2.0.weight, up_blocks.2.resnets.1.conv2.weight, mid_block.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.1.temp_convs.0.conv1.2.weight, down_blocks.2.downsamplers.0.conv.weight, up_blocks.3.resnets.0.conv_shortcut.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.1.temp_attentions.0.proj_in.weight, down_blocks.2.temp_attentions.1.proj_in.weight, mid_block.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.temp_convs.0.conv1.0.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.attentions.1.transformer_blocks.0.norm2.bias, down_blocks.2.resnets.1.norm1.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm2.bias, down_blocks.3.temp_convs.1.conv2.0.weight, mid_block.temp_convs.0.conv4.3.weight, transformer_in.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm1.bias, down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight, down_blocks.3.temp_convs.0.conv4.0.weight, down_blocks.1.temp_convs.1.conv4.0.bias, down_blocks.1.temp_attentions.1.proj_out.bias, down_blocks.1.temp_convs.0.conv4.0.weight, down_blocks.3.resnets.1.time_emb_proj.weight, time_embedding.linear_2.weight, up_blocks.2.temp_convs.1.conv3.0.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, down_blocks.3.temp_convs.1.conv3.0.weight, up_blocks.3.temp_convs.2.conv4.0.bias, up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm3.bias, up_blocks.3.temp_convs.0.conv4.0.bias, up_blocks.0.temp_convs.0.conv3.3.weight, up_blocks.2.temp_convs.2.conv3.0.weight, down_blocks.2.temp_attentions.0.norm.bias, up_blocks.1.temp_attentions.0.proj_in.bias, up_blocks.3.attentions.1.proj_in.bias, transformer_in.transformer_blocks.0.ff.net.2.weight, up_blocks.1.temp_convs.1.conv3.3.bias, transformer_in.transformer_blocks.0.norm1.weight, up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias, down_blocks.2.temp_convs.1.conv4.0.bias, up_blocks.3.resnets.0.conv2.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.3.temp_convs.2.conv4.0.weight, up_blocks.0.temp_convs.1.conv4.0.bias, up_blocks.1.attentions.1.proj_in.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm1.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.0.temp_convs.0.conv3.3.weight, up_blocks.1.attentions.2.proj_out.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.resnets.1.norm1.weight, up_blocks.1.temp_attentions.2.proj_out.weight, down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.resnets.0.time_emb_proj.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm2.bias, mid_block.temp_attentions.0.proj_in.bias, up_blocks.1.temp_convs.2.conv2.3.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.ff.net.2.weight, down_blocks.0.resnets.1.conv2.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, mid_block.resnets.1.conv2.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight, mid_block.temp_convs.1.conv3.3.weight, up_blocks.0.resnets.2.time_emb_proj.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.0.temp_convs.2.conv1.2.bias, transformer_in.transformer_blocks.0.attn1.to_out.0.weight, transformer_in.proj_in.weight, down_blocks.2.temp_convs.1.conv2.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.0.resnets.2.norm2.bias, mid_block.temp_convs.0.conv4.0.weight, up_blocks.0.resnets.2.norm1.weight, up_blocks.3.temp_convs.0.conv4.3.weight, up_blocks.2.resnets.1.norm1.bias, down_blocks.2.temp_convs.1.conv2.3.bias, down_blocks.2.temp_attentions.0.proj_out.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.0.temp_attentions.1.norm.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn2.to_q.weight, conv_out.bias, down_blocks.0.resnets.0.norm1.bias, down_blocks.1.temp_convs.1.conv1.0.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm1.bias, up_blocks.2.temp_convs.0.conv4.3.bias, up_blocks.2.attentions.1.proj_in.weight, up_blocks.2.resnets.1.conv1.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.temp_attentions.1.proj_in.weight, up_blocks.1.attentions.2.proj_in.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias, up_blocks.2.temp_convs.2.conv1.0.weight, up_blocks.2.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.2.transformer_blocks.0.norm2.weight, mid_block.attentions.0.transformer_blocks.0.norm1.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.resnets.2.conv1.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, down_blocks.2.temp_convs.1.conv1.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.0.temp_convs.0.conv4.0.weight, up_blocks.2.temp_convs.2.conv3.3.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.ff.net.2.weight, up_blocks.1.resnets.2.time_emb_proj.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.3.temp_convs.1.conv2.3.weight, up_blocks.0.resnets.2.time_emb_proj.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.resnets.0.conv1.weight, up_blocks.1.resnets.1.conv2.weight, down_blocks.2.temp_attentions.0.proj_in.bias, up_blocks.1.temp_attentions.1.proj_out.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm3.weight, down_blocks.3.resnets.1.conv1.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm1.weight, mid_block.temp_convs.1.conv4.3.weight, down_blocks.1.temp_attentions.0.proj_out.weight, up_blocks.3.temp_convs.1.conv3.0.bias, mid_block.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm2.bias, down_blocks.1.attentions.0.norm.weight, mid_block.temp_convs.1.conv4.0.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm3.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.temp_convs.2.conv3.3.bias, up_blocks.0.resnets.1.norm2.bias, up_blocks.0.temp_convs.1.conv4.3.bias, down_blocks.0.temp_convs.0.conv1.2.bias, down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias, up_blocks.3.temp_attentions.0.proj_out.weight, down_blocks.1.attentions.1.norm.weight, down_blocks.0.temp_convs.0.conv1.0.weight, down_blocks.2.resnets.1.conv2.weight, up_blocks.3.attentions.2.norm.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.attentions.1.proj_out.weight, down_blocks.2.attentions.1.proj_out.bias, down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.resnets.1.conv2.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.temp_convs.1.conv4.0.weight, mid_block.temp_convs.0.conv2.3.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm1.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.resnets.0.norm1.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.2.temp_convs.0.conv2.3.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.ff.net.2.weight, down_blocks.3.resnets.1.norm1.bias, down_blocks.0.attentions.1.norm.bias, up_blocks.2.temp_convs.2.conv1.2.bias, down_blocks.2.temp_attentions.1.norm.weight, up_blocks.2.resnets.2.conv1.bias, up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm2.weight, down_blocks.2.resnets.0.norm1.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias, down_blocks.2.temp_convs.1.conv3.3.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, down_blocks.0.resnets.0.norm1.weight, up_blocks.0.temp_convs.0.conv2.3.weight, up_blocks.3.temp_attentions.2.proj_out.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight, down_blocks.1.temp_convs.0.conv3.3.weight, up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.temp_convs.1.conv4.0.bias, down_blocks.2.attentions.0.proj_out.weight, up_blocks.1.temp_convs.0.conv2.0.bias, up_blocks.1.resnets.0.norm2.bias, mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.resnets.1.conv1.weight, down_blocks.3.temp_convs.0.conv4.0.bias, up_blocks.0.temp_convs.0.conv3.3.bias, up_blocks.3.temp_convs.0.conv2.3.bias, down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias, up_blocks.0.temp_convs.1.conv2.0.weight, down_blocks.0.temp_attentions.0.proj_in.weight, up_blocks.3.attentions.1.transformer_blocks.0.norm1.bias, down_blocks.1.resnets.0.time_emb_proj.bias, down_blocks.1.temp_attentions.1.proj_in.weight, up_blocks.3.temp_convs.1.conv4.0.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_convs.0.conv1.2.weight, up_blocks.3.resnets.1.conv1.bias, up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.attentions.2.norm.bias, up_blocks.1.temp_convs.2.conv3.0.weight, mid_block.temp_attentions.0.proj_in.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.1.proj_in.bias, up_blocks.3.temp_convs.0.conv1.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_k.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm2.bias, up_blocks.0.resnets.1.norm2.weight, down_blocks.0.resnets.0.time_emb_proj.weight, up_blocks.0.temp_convs.2.conv4.3.weight, up_blocks.2.temp_attentions.1.norm.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm3.bias, up_blocks.3.attentions.0.transformer_blocks.0.norm3.bias, mid_block.temp_convs.1.conv3.3.bias, down_blocks.3.resnets.1.conv2.weight, down_blocks.0.temp_convs.1.conv1.0.bias, down_blocks.2.attentions.0.norm.bias, down_blocks.1.temp_convs.0.conv3.0.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.2.attentions.1.norm.weight, transformer_in.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.2.attentions.0.transformer_blocks.0.norm1.weight, down_blocks.1.temp_convs.1.conv1.2.bias, down_blocks.2.attentions.0.proj_in.weight, up_blocks.1.temp_attentions.2.proj_in.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.0.temp_convs.1.conv1.0.weight, conv_norm_out.bias, down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight, up_blocks.1.temp_convs.1.conv3.0.bias, down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias, down_blocks.3.temp_convs.1.conv1.2.bias, down_blocks.1.temp_convs.0.conv4.3.bias, down_blocks.1.attentions.0.norm.bias, mid_block.temp_convs.1.conv1.2.weight, up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, mid_block.temp_convs.1.conv2.3.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn2.to_k.weight, down_blocks.0.downsamplers.0.conv.bias, up_blocks.0.temp_convs.1.conv3.3.bias, down_blocks.1.temp_convs.0.conv2.3.weight, up_blocks.1.temp_convs.0.conv1.0.bias, up_blocks.1.temp_attentions.0.norm.weight, down_blocks.3.resnets.0.conv2.bias, mid_block.temp_convs.1.conv1.2.bias, up_blocks.2.temp_convs.2.conv2.3.bias, up_blocks.0.resnets.0.conv_shortcut.bias, up_blocks.3.attentions.1.proj_in.weight, down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm3.bias, up_blocks.2.temp_convs.1.conv3.3.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.0.resnets.2.conv_shortcut.weight, up_blocks.3.temp_convs.0.conv4.3.bias, mid_block.temp_convs.1.conv3.0.weight, up_blocks.2.attentions.1.norm.bias, up_blocks.0.temp_convs.2.conv4.0.bias, down_blocks.2.temp_convs.0.conv4.3.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.3.resnets.0.conv2.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.ff.net.2.bias, up_blocks.2.temp_convs.2.conv4.3.weight, mid_block.resnets.1.norm1.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm1.weight, up_blocks.3.attentions.1.proj_out.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_convs.0.conv1.0.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.3.resnets.2.conv1.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.temp_convs.0.conv1.2.bias, up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias, up_blocks.3.temp_attentions.0.proj_out.bias, mid_block.temp_convs.0.conv2.3.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.temp_convs.0.conv1.0.bias, up_blocks.3.attentions.2.transformer_blocks.0.norm3.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.0.temp_convs.2.conv3.0.bias, up_blocks.1.temp_convs.1.conv4.3.weight, up_blocks.3.resnets.1.conv2.weight, down_blocks.1.resnets.1.conv2.weight, up_blocks.3.temp_convs.2.conv1.0.weight, down_blocks.1.temp_convs.0.conv2.0.weight, down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight, down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight, down_blocks.2.temp_convs.1.conv3.3.bias, down_blocks.1.temp_convs.1.conv4.0.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.0.temp_attentions.0.norm.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.0.resnets.1.time_emb_proj.bias, up_blocks.3.temp_attentions.1.norm.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.3.temp_convs.2.conv2.3.bias, up_blocks.0.resnets.1.conv_shortcut.bias, down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.2.temp_convs.0.conv3.3.weight, up_blocks.1.temp_convs.1.conv2.3.bias, mid_block.temp_convs.0.conv3.0.weight, down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.2.attentions.0.proj_out.bias, up_blocks.2.temp_convs.0.conv1.2.weight, up_blocks.3.attentions.0.proj_out.bias, down_blocks.2.temp_convs.1.conv2.3.weight, up_blocks.2.temp_convs.1.conv2.0.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm2.bias, down_blocks.0.temp_convs.0.conv3.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm3.weight, down_blocks.2.temp_convs.0.conv1.2.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight, down_blocks.0.resnets.1.time_emb_proj.weight, down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.0.temp_convs.2.conv2.3.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.temp_convs.1.conv1.0.weight, up_blocks.3.temp_attentions.0.norm.weight, down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, mid_block.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.0.temp_convs.1.conv3.3.weight, down_blocks.2.resnets.1.time_emb_proj.weight, up_blocks.0.temp_convs.0.conv2.3.bias, up_blocks.3.resnets.2.norm1.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.0.resnets.0.time_emb_proj.bias, up_blocks.3.attentions.2.proj_out.weight, conv_out.weight, down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm1.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.resnets.1.conv2.bias, down_blocks.2.resnets.0.time_emb_proj.weight, up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias, up_blocks.3.attentions.2.transformer_blocks.0.norm3.bias, up_blocks.1.temp_convs.1.conv2.0.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.0.temp_convs.1.conv1.0.bias, up_blocks.3.temp_convs.2.conv3.3.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.2.temp_convs.0.conv4.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, down_blocks.0.temp_convs.0.conv1.0.bias, up_blocks.1.temp_attentions.2.proj_out.bias, up_blocks.1.temp_convs.0.conv2.3.bias, up_blocks.0.temp_convs.2.conv3.3.bias, mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.2.resnets.0.conv2.weight, down_blocks.1.temp_attentions.1.proj_out.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.temp_attentions.2.norm.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, transformer_in.transformer_blocks.0.attn1.to_k.weight, down_blocks.2.attentions.1.norm.weight, up_blocks.2.resnets.0.norm1.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_k.weight, up_blocks.0.temp_convs.0.conv3.0.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.norm1.bias, up_blocks.3.attentions.2.proj_in.weight, down_blocks.2.temp_attentions.1.proj_out.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.1.attentions.0.proj_out.bias, down_blocks.2.temp_convs.1.conv4.0.weight, up_blocks.2.upsamplers.0.conv.weight, up_blocks.2.resnets.2.conv2.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.attentions.0.transformer_blocks.0.norm3.bias, up_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.1.temp_convs.0.conv2.0.bias, up_blocks.1.temp_convs.2.conv3.0.bias, mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm3.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm3.bias, down_blocks.3.resnets.0.norm1.bias, up_blocks.0.temp_convs.2.conv4.0.weight, up_blocks.2.attentions.1.proj_out.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm3.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm3.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.temp_convs.2.conv4.0.bias, up_blocks.3.temp_convs.1.conv2.3.bias, transformer_in.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.0.resnets.0.conv2.weight, up_blocks.3.attentions.0.transformer_blocks.0.norm1.bias, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.temp_convs.0.conv3.3.bias, up_blocks.3.attentions.2.proj_out.bias, up_blocks.0.temp_convs.2.conv2.3.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, mid_block.attentions.0.transformer_blocks.0.norm1.weight, up_blocks.1.resnets.1.time_emb_proj.weight, up_blocks.1.upsamplers.0.conv.bias, up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.3.attentions.1.transformer_blocks.0.norm3.weight, mid_block.resnets.0.conv2.bias, up_blocks.2.temp_attentions.0.proj_in.bias, time_embedding.linear_1.weight, down_blocks.0.temp_convs.1.conv2.3.weight, up_blocks.3.temp_convs.0.conv4.0.weight, down_blocks.0.resnets.0.time_emb_proj.bias, up_blocks.3.resnets.2.norm2.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm1.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm2.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm3.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.resnets.1.norm2.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight, conv_in.weight, up_blocks.1.attentions.1.proj_in.weight, down_blocks.2.attentions.0.norm.weight, down_blocks.0.resnets.0.norm2.weight, down_blocks.2.temp_attentions.1.proj_out.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.1.temp_convs.0.conv3.3.bias, down_blocks.2.temp_attentions.0.proj_in.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm2.weight, down_blocks.0.attentions.0.proj_out.bias, up_blocks.0.temp_convs.1.conv1.2.weight, mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, up_blocks.3.temp_convs.2.conv2.0.bias, down_blocks.3.resnets.1.norm2.weight, up_blocks.3.resnets.2.conv1.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.1.temp_convs.0.conv4.3.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.bias, down_blocks.0.temp_convs.1.conv3.3.bias, up_blocks.3.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.2.resnets.0.conv1.bias, down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.temp_attentions.0.proj_in.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight, down_blocks.2.temp_convs.0.conv1.0.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.0.resnets.0.time_emb_proj.weight, up_blocks.3.temp_convs.1.conv1.2.weight, up_blocks.3.resnets.0.norm1.weight, down_blocks.2.temp_convs.0.conv2.0.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.attentions.0.norm.weight, up_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.2.resnets.0.conv1.bias, mid_block.temp_convs.0.conv2.0.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_v.weight, mid_block.temp_convs.0.conv3.3.weight, up_blocks.2.resnets.2.norm2.weight, down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias, down_blocks.2.resnets.0.conv_shortcut.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.attentions.2.norm.weight, up_blocks.1.resnets.2.time_emb_proj.weight, mid_block.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.resnets.0.norm2.weight, down_blocks.0.temp_convs.0.conv1.2.weight, down_blocks.2.attentions.0.proj_in.bias, mid_block.resnets.1.norm1.weight, mid_block.temp_attentions.0.proj_out.bias, up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm2.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_q.weight, down_blocks.2.resnets.0.conv1.weight, mid_block.attentions.0.transformer_blocks.0.norm3.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm2.weight, mid_block.attentions.0.norm.bias, down_blocks.1.resnets.1.conv1.bias, up_blocks.1.resnets.1.norm1.weight, down_blocks.1.temp_convs.1.conv4.3.bias, up_blocks.2.resnets.0.conv_shortcut.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.attentions.0.transformer_blocks.0.norm1.bias, up_blocks.1.temp_convs.1.conv2.0.bias, up_blocks.3.temp_attentions.1.proj_in.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight, up_blocks.3.attentions.1.transformer_blocks.0.norm2.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, mid_block.resnets.1.conv2.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.0.resnets.1.conv1.weight, down_blocks.2.temp_convs.0.conv3.3.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.temp_convs.0.conv4.0.weight, down_blocks.1.temp_attentions.1.proj_in.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm1.bias, up_blocks.1.resnets.0.conv_shortcut.bias, up_blocks.2.resnets.2.norm1.weight, up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.1.attentions.1.proj_in.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm1.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.3.attentions.1.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.3.attentions.0.proj_in.weight, up_blocks.2.temp_convs.0.conv1.0.bias, up_blocks.0.temp_convs.2.conv2.0.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.1.temp_convs.1.conv4.3.bias, up_blocks.1.temp_attentions.0.norm.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm1.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.1.temp_attentions.2.proj_in.weight, down_blocks.3.resnets.0.conv1.weight, up_blocks.0.resnets.2.conv1.weight, down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, mid_block.resnets.1.time_emb_proj.bias, up_blocks.3.temp_convs.0.conv3.0.weight, down_blocks.1.temp_convs.0.conv1.2.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm3.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight, up_blocks.3.attentions.2.proj_in.bias, down_blocks.0.temp_convs.1.conv1.2.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.attentions.0.proj_out.weight, down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm2.bias, up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight, down_blocks.0.temp_attentions.1.norm.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm3.bias, down_blocks.0.attentions.0.proj_in.weight, mid_block.temp_attentions.0.transformer_blocks.0.norm1.weight, up_blocks.3.attentions.1.transformer_blocks.0.norm1.weight, up_blocks.3.resnets.1.conv2.bias, up_blocks.0.resnets.0.conv1.weight, up_blocks.0.temp_convs.0.conv1.0.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.0.temp_convs.2.conv1.0.bias, down_blocks.2.temp_convs.1.conv4.3.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.resnets.1.norm1.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, transformer_in.transformer_blocks.0.norm1.bias, mid_block.temp_convs.0.conv1.2.bias, down_blocks.1.resnets.1.conv2.bias, up_blocks.2.attentions.1.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.1.norm.bias, down_blocks.3.temp_convs.1.conv2.0.bias, up_blocks.3.resnets.0.time_emb_proj.weight, up_blocks.0.temp_convs.0.conv1.0.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, mid_block.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, mid_block.attentions.0.proj_out.bias, up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.0.temp_convs.0.conv4.3.weight, down_blocks.1.resnets.0.conv1.bias, mid_block.temp_convs.0.conv4.3.bias, down_blocks.3.temp_convs.0.conv1.2.weight, mid_block.temp_attentions.0.transformer_blocks.0.norm3.bias, up_blocks.2.attentions.0.transformer_blocks.0.norm2.bias, down_blocks.3.resnets.1.conv1.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm3.bias, down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias, up_blocks.3.resnets.2.conv_shortcut.bias, down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias, transformer_in.transformer_blocks.0.attn2.to_k.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm3.weight, up_blocks.1.temp_attentions.2.norm.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.2.temp_convs.1.conv2.0.bias, up_blocks.0.temp_convs.0.conv1.2.bias, mid_block.resnets.0.time_emb_proj.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.temp_convs.2.conv4.3.weight, up_blocks.1.resnets.0.norm2.weight, up_blocks.2.temp_convs.0.conv3.0.weight, up_blocks.3.resnets.2.conv2.weight, up_blocks.3.resnets.2.time_emb_proj.weight, up_blocks.0.temp_convs.0.conv2.0.bias, up_blocks.2.temp_convs.2.conv4.3.bias, up_blocks.3.attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.2.temp_convs.0.conv2.0.bias, up_blocks.3.temp_attentions.2.proj_out.bias, up_blocks.3.attentions.0.transformer_blocks.0.norm1.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm3.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.3.temp_convs.1.conv4.3.bias, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.temp_convs.0.conv4.3.bias, down_blocks.1.resnets.0.norm1.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.0.temp_convs.1.conv3.0.bias, up_blocks.3.resnets.2.time_emb_proj.bias, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.resnets.0.conv2.weight, down_blocks.3.temp_convs.1.conv4.0.weight, up_blocks.1.temp_attentions.0.proj_in.weight, down_blocks.0.attentions.0.proj_in.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.attentions.2.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.resnets.0.norm1.bias, mid_block.temp_convs.1.conv2.0.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.temp_convs.1.conv2.3.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.temp_attentions.1.proj_in.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn1.to_q.weight, mid_block.temp_convs.0.conv1.0.weight, transformer_in.transformer_blocks.0.ff.net.2.bias, up_blocks.0.resnets.1.conv_shortcut.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm2.bias, up_blocks.3.temp_convs.1.conv3.3.weight, up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.resnets.1.norm2.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.temp_convs.2.conv1.2.weight, down_blocks.1.temp_convs.1.conv3.0.bias, up_blocks.2.resnets.0.norm2.bias, down_blocks.3.temp_convs.1.conv3.3.weight, mid_block.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight, down_blocks.0.temp_convs.0.conv4.0.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.1.attentions.0.proj_in.weight, up_blocks.1.temp_convs.0.conv2.3.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight, down_blocks.0.temp_attentions.1.proj_out.weight, down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias, mid_block.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.attentions.0.norm.weight, down_blocks.2.resnets.0.norm1.bias, down_blocks.0.temp_convs.0.conv2.3.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.temp_convs.0.conv4.0.bias, down_blocks.2.resnets.1.conv2.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm1.weight, down_blocks.1.temp_attentions.0.proj_out.bias, mid_block.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm3.bias, up_blocks.0.temp_convs.2.conv3.3.weight, up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm1.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm2.weight, up_blocks.1.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.resnets.1.conv_shortcut.weight, up_blocks.3.resnets.0.norm2.weight, transformer_in.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.temp_attentions.0.transformer_blocks.0.norm3.weight, up_blocks.3.resnets.0.conv_shortcut.bias, up_blocks.2.resnets.2.conv_shortcut.bias, up_blocks.2.attentions.0.norm.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm2.bias, mid_block.temp_convs.0.conv3.3.bias, down_blocks.0.resnets.1.norm2.bias, down_blocks.2.temp_convs.0.conv3.0.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.temp_convs.0.conv4.0.weight, up_blocks.3.temp_convs.0.conv3.3.weight, up_blocks.3.attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm3.bias, up_blocks.2.temp_convs.1.conv3.0.weight, up_blocks.2.resnets.2.time_emb_proj.bias, down_blocks.0.resnets.1.norm1.weight, up_blocks.3.temp_convs.1.conv1.0.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight, up_blocks.3.attentions.0.transformer_blocks.0.norm3.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.0.temp_convs.0.conv4.3.bias, down_blocks.3.resnets.0.norm2.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.3.temp_convs.1.conv3.0.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.2.bias, down_blocks.1.resnets.0.norm2.bias, up_blocks.1.attentions.1.proj_out.weight, up_blocks.1.resnets.2.conv_shortcut.weight, up_blocks.1.temp_attentions.1.norm.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.1.resnets.0.time_emb_proj.bias, down_blocks.0.resnets.0.conv1.weight, up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm1.weight, up_blocks.1.temp_convs.2.conv2.0.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm2.bias, down_blocks.2.temp_convs.0.conv4.0.bias, up_blocks.2.resnets.2.conv_shortcut.weight, up_blocks.3.attentions.2.norm.weight, up_blocks.1.attentions.0.proj_in.bias, up_blocks.2.resnets.1.conv_shortcut.bias, down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight, down_blocks.1.attentions.1.proj_out.weight, up_blocks.1.resnets.1.conv2.bias, down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias, mid_block.attentions.0.transformer_blocks.0.norm3.weight, mid_block.temp_convs.1.conv2.3.weight, up_blocks.1.temp_attentions.1.proj_in.weight, down_blocks.0.temp_convs.0.conv4.3.weight, up_blocks.3.temp_convs.1.conv3.3.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.0.downsamplers.0.conv.weight, down_blocks.1.temp_convs.1.conv3.0.weight, up_blocks.2.resnets.0.time_emb_proj.weight, down_blocks.0.temp_convs.1.conv4.3.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.2.temp_attentions.0.proj_out.weight, up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight, mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.3.temp_attentions.1.proj_out.bias, up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias, up_blocks.2.attentions.2.transformer_blocks.0.norm3.weight, up_blocks.1.resnets.2.conv2.weight, down_blocks.1.temp_convs.1.conv3.3.bias, up_blocks.3.resnets.2.norm1.weight, up_blocks.1.attentions.0.norm.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_q.weight, conv_norm_out.weight, down_blocks.3.temp_convs.1.conv4.3.weight, up_blocks.1.temp_convs.0.conv2.0.weight, down_blocks.2.resnets.1.norm1.weight, down_blocks.2.resnets.1.conv1.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm2.bias, up_blocks.3.temp_attentions.2.transformer_blocks.0.norm2.weight, down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.2.attentions.0.proj_out.bias, up_blocks.2.attentions.1.proj_out.weight, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.ff.net.2.bias, down_blocks.1.attentions.1.proj_in.weight, mid_block.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.norm2.weight, up_blocks.1.temp_convs.2.conv4.0.bias, up_blocks.0.resnets.0.conv2.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.0.resnets.1.conv2.weight, up_blocks.1.temp_convs.1.conv4.0.bias, down_blocks.0.attentions.1.norm.weight, down_blocks.3.temp_convs.0.conv3.0.weight, up_blocks.2.temp_convs.1.conv1.2.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight, up_blocks.3.temp_convs.0.conv3.0.bias, up_blocks.2.resnets.0.time_emb_proj.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.norm3.bias, up_blocks.1.temp_convs.1.conv1.2.weight, down_blocks.3.temp_convs.0.conv3.3.weight, down_blocks.0.temp_attentions.0.proj_in.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn1.to_k.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight, transformer_in.norm.weight, up_blocks.3.temp_attentions.2.proj_in.weight, up_blocks.3.temp_convs.2.conv1.2.bias, mid_block.resnets.0.norm1.weight, up_blocks.2.temp_attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.2.temp_attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.attentions.0.proj_in.bias, up_blocks.2.resnets.2.time_emb_proj.weight, down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight, down_blocks.1.temp_convs.1.conv3.3.weight, up_blocks.2.attentions.2.proj_out.weight, down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.attentions.1.proj_out.weight, up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias, up_blocks.1.resnets.0.conv_shortcut.weight, transformer_in.proj_in.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.3.temp_convs.2.conv4.3.weight, up_blocks.2.temp_convs.0.conv4.0.weight, down_blocks.0.temp_attentions.0.proj_out.bias, mid_block.temp_convs.1.conv4.3.bias, up_blocks.0.temp_convs.1.conv3.0.weight, mid_block.temp_convs.1.conv1.0.weight, up_blocks.1.temp_convs.2.conv1.0.bias, up_blocks.1.attentions.0.proj_out.bias, down_blocks.2.temp_convs.1.conv2.0.weight, down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.0.temp_convs.2.conv1.0.weight, up_blocks.2.temp_attentions.0.norm.weight, down_blocks.2.temp_convs.0.conv2.0.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, up_blocks.3.resnets.1.conv_shortcut.bias, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.0.resnets.2.conv_shortcut.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm1.weight, down_blocks.0.temp_attentions.1.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.temp_convs.2.conv3.0.weight, up_blocks.1.temp_attentions.1.norm.weight, up_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.ff.net.2.weight, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm1.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_q.weight, down_blocks.1.temp_attentions.1.norm.bias, down_blocks.2.resnets.0.conv_shortcut.bias, up_blocks.0.temp_convs.2.conv1.2.weight, up_blocks.1.resnets.2.norm2.weight, down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.temp_attentions.0.norm.bias, time_embedding.linear_2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight, down_blocks.1.attentions.1.norm.bias, down_blocks.2.resnets.1.norm2.weight, up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.bias, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.temp_attentions.1.transformer_blocks.0.norm2.weight, down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight, down_blocks.0.temp_convs.1.conv3.0.weight, down_blocks.1.temp_attentions.1.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.3.temp_convs.0.conv2.0.weight, up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm3.bias, mid_block.resnets.0.norm2.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.ff.net.2.bias, up_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight, down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias, up_blocks.0.temp_convs.0.conv2.0.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm2.weight, up_blocks.2.resnets.2.conv2.weight, down_blocks.0.temp_convs.1.conv3.0.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.resnets.2.norm2.weight, mid_block.temp_attentions.0.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.0.transformer_blocks.0.attn1.to_k.weight, up_blocks.2.temp_convs.2.conv1.2.weight, down_blocks.0.resnets.0.conv2.bias, up_blocks.0.resnets.0.norm1.bias, up_blocks.0.resnets.0.norm2.bias, up_blocks.2.temp_convs.1.conv4.3.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm3.bias, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn2.to_v.weight, up_blocks.1.temp_convs.2.conv1.0.weight, up_blocks.2.attentions.2.proj_out.bias, mid_block.attentions.0.proj_in.weight, down_blocks.3.temp_convs.1.conv1.0.bias, up_blocks.0.resnets.2.norm2.weight, down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.bias, down_blocks.2.resnets.0.conv2.weight, up_blocks.3.temp_convs.2.conv4.3.bias, up_blocks.3.temp_convs.2.conv2.3.weight, up_blocks.1.temp_attentions.0.transformer_blocks.0.norm1.weight, down_blocks.3.temp_convs.1.conv4.0.bias, mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.3.temp_attentions.1.transformer_blocks.0.norm3.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn1.to_out.0.weight, up_blocks.2.attentions.0.transformer_blocks.0.norm3.weight, up_blocks.3.temp_attentions.2.norm.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm1.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.weight, transformer_in.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.resnets.0.norm2.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.attn2.to_q.weight, down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight, down_blocks.2.temp_attentions.1.proj_in.bias, up_blocks.1.temp_attentions.0.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.resnets.0.conv2.weight, up_blocks.0.temp_convs.1.conv1.0.weight, up_blocks.2.attentions.2.transformer_blocks.0.ff.net.2.bias, up_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.ff.net.0.proj.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.attn1.to_out.0.bias, up_blocks.1.resnets.0.conv1.bias, up_blocks.3.attentions.2.transformer_blocks.0.ff.net.2.weight, down_blocks.3.resnets.1.time_emb_proj.bias, up_blocks.3.attentions.2.transformer_blocks.0.norm2.bias, mid_block.resnets.1.conv1.weight, up_blocks.3.temp_attentions.0.transformer_blocks.0.norm3.weight, up_blocks.2.attentions.2.proj_in.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.norm1.weight, up_blocks.1.attentions.2.proj_out.weight, up_blocks.2.temp_convs.1.conv4.3.bias, down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight, down_blocks.1.resnets.0.norm1.bias, up_blocks.3.attentions.0.transformer_blocks.0.norm2.weight, up_blocks.3.attentions.1.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.resnets.1.norm2.bias, up_blocks.2.attentions.1.transformer_blocks.0.norm1.weight, down_blocks.2.temp_convs.0.conv1.0.weight, up_blocks.1.temp_attentions.0.proj_out.weight, down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight, up_blocks.0.temp_convs.2.conv4.3.bias, down_blocks.1.temp_convs.0.conv2.3.bias, up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight, down_blocks.1.resnets.0.time_emb_proj.weight, down_blocks.1.attentions.1.proj_out.bias, down_blocks.2.downsamplers.0.conv.bias, up_blocks.1.resnets.2.conv_shortcut.bias, down_blocks.1.resnets.1.norm2.bias, mid_block.temp_convs.0.conv2.0.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm2.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.ff.net.2.weight, up_blocks.2.attentions.2.transformer_blocks.0.attn1.to_v.weight, down_blocks.3.resnets.1.norm2.bias, up_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight, down_blocks.3.resnets.1.conv2.bias, down_blocks.1.temp_attentions.0.transformer_blocks.0.attn1.to_k.weight, down_blocks.2.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, up_blocks.1.temp_convs.2.conv3.3.weight, mid_block.temp_attentions.0.norm.bias, up_blocks.3.temp_convs.2.conv1.0.bias, down_blocks.0.temp_attentions.0.transformer_blocks.0.ff.net.2.bias, down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.norm1.bias, up_blocks.3.attentions.1.norm.weight, down_blocks.0.temp_attentions.1.proj_in.bias, down_blocks.0.temp_attentions.1.transformer_blocks.0.norm2.weight, down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight, up_blocks.2.resnets.1.conv1.weight, down_blocks.0.temp_convs.1.conv4.3.weight, up_blocks.1.temp_attentions.2.transformer_blocks.0.attn1.to_v.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn1.to_v.weight, down_blocks.0.temp_convs.1.conv2.3.bias, up_blocks.3.temp_attentions.0.norm.bias, down_blocks.2.temp_attentions.1.transformer_blocks.0.norm3.weight, transformer_in.transformer_blocks.0.norm3.bias, up_blocks.3.attentions.2.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.2.temp_attentions.2.proj_in.bias, transformer_in.transformer_blocks.0.attn2.to_q.weight, down_blocks.0.resnets.0.norm2.bias, up_blocks.0.resnets.2.conv2.bias, mid_block.temp_convs.0.conv3.0.bias, up_blocks.2.attentions.2.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn2.to_k.weight, up_blocks.3.temp_convs.1.conv3.0.weight, up_blocks.2.temp_attentions.2.transformer_blocks.0.attn2.to_out.0.weight, up_blocks.2.temp_convs.1.conv2.3.weight, up_blocks.1.resnets.1.conv_shortcut.weight, up_blocks.2.temp_convs.0.conv2.3.weight, down_blocks.0.temp_convs.1.conv3.3.weight, down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight, down_blocks.1.resnets.0.conv1.weight, down_blocks.0.temp_convs.1.conv2.0.bias, down_blocks.3.temp_convs.0.conv2.3.bias, up_blocks.3.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, down_blocks.2.temp_attentions.0.transformer_blocks.0.norm2.bias, up_blocks.1.temp_attentions.1.transformer_blocks.0.norm2.weight, down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight, down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias, up_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias, down_blocks.1.temp_attentions.1.transformer_blocks.0.attn1.to_v.weight, up_blocks.1.temp_convs.0.conv3.0.weight, down_blocks.2.temp_convs.1.conv3.0.weight, down_blocks.2.attentions.1.proj_in.bias, up_blocks.3.attentions.0.transformer_blocks.0.attn2.to_out.0.bias, up_blocks.1.temp_convs.0.conv3.3.weight, up_blocks.3.temp_attentions.1.norm.weight, up_blocks.2.attentions.0.norm.weight, down_blocks.1.temp_attentions.0.transformer_blocks.0.norm2.bias, up_blocks.3.temp_convs.1.conv1.2.bias. \n",
            " Please make sure to pass `low_cpu_mem_usage=False` and `device_map=None` if you want to randomly initialize those weights or else make sure your checkpoint file is correct.\n"
          ]
        }
      ],
      "source": [
        "!python train.py --config ./configs/my_config_hq.yaml --experiment_num=0 --use_wandb=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DotzCfQbShbf"
      },
      "source": [
        "# Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6iy3bIOhfgE",
        "outputId": "4296fae8-b85a-49e9-8198-27c29cf81f79"
      },
      "outputs": [],
      "source": [
        "# !python inference.py \\\n",
        "#     --model '/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/outputs/train_2024-01-13T20-29-09/checkpoint-50\" --prompt \"Simplify (x+1)(x-1) explained' \\\n",
        "#     --prompt 'Please simplify this expression: (x+1)(x-1)' \\\n",
        "#     --neg_prompt \"watermark+++, text, shutterstock text, shutterstock++, blurry, ugly, username, url, low resolution, low quality\" \\\n",
        "#     --num-frames 16 \\\n",
        "#     --window-size 12 \\\n",
        "#     --width 128 \\\n",
        "#     --height 128 \\\n",
        "#     --sdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q1DttecwShbf"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from diffusers import DPMSolverMultistepScheduler, DDPMScheduler, TextToVideoSDPipeline\n",
        "# from diffusers.utils import export_to_video\n",
        "# import imageio\n",
        "# from compel import Compel\n",
        "\n",
        "# def to_video(fn: str, frames: list[np.ndarray], fps: int) -> str:\n",
        "#     # out_file = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "#     writer = imageio.get_writer(fn, format='FFMPEG', fps=fps)\n",
        "#     for frame in frames:\n",
        "#         writer.append_data(frame)\n",
        "#     writer.close()\n",
        "#     return fn\n",
        "\n",
        "# my_trained_model_path = f\"{WORKING_DIR}/Text-To-Video-Finetuning/outputs/train_2023-12-06T21-23-48/checkpoint-12500\"\n",
        "# # pipe = TextToVideoSDPipeline.from_pretrained(my_trained_model_path,torch_dtype=torch.float16, variant=\"fp16\")\n",
        "# # compel = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\n",
        "# # pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "# # pipe.enable_model_cpu_offload()\n",
        "\n",
        "# # seed = random.randint(0, 1000000)\n",
        "# # generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "# # prompt = \"(x+1)(x-1) expression simplified\"\n",
        "# # neg_prompt = \"watermark+++, text, shutterstock text, shutterstock++, blurry, ugly, username, url, low resolution, low quality\"\n",
        "# # prompt_embeds = compel.build_conditioning_tensor(prompt)\n",
        "# # neg_prompt_embeds = compel.build_conditioning_tensor(neg_prompt)\n",
        "# # video_frames = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=neg_prompt_embeds, num_frames=100, width=384, height=256, num_inference_steps=50, guidance_scale=9, generator=generator).frames\n",
        "\n",
        "# # prompt_string = prompt.replace(\" \", \"-\")\n",
        "# # out_file = f\"{WORKING_DIR}/\"+prompt_string+\"-seed\"+str(seed)+\".mp4\"\n",
        "# # video_path = to_video(out_file, video_frames, 24)\n",
        "# # video_path = export_to_video(video_frames, out_file)\n",
        "# # print(video_path+ \" is ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mb0SZgJUShbg",
        "outputId": "cffc7720-ef56-4125-e94a-00826570bce4"
      },
      "outputs": [],
      "source": [
        "# !pip freeze | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ipW13ByAShbg",
        "outputId": "3daf3dc6-568e-4ad7-f988-5b62fd8ba982"
      },
      "outputs": [],
      "source": [
        "# !pip freeze | grep diffusers"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
