{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9O8VOTiShbZ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AppimateSA/AutoVisual/blob/text2video_stablediffusion/notebooks/Text-To-Video-Finetuning.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FPL6HGLShbb"
      },
      "source": [
        "# Prepare the enviornment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl9M30V4Shbb",
        "outputId": "7082a1d8-031f-4e39-bd79-b66ffae3b49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import platform\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    WORKING_DIR = '.'\n",
        "    IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "    WORKING_DIR = '/content'\n",
        "    drive.mount('/content/drive',  force_remount=True) # Mount drive in order access Google drive\n",
        "if IN_COLAB:\n",
        "    sys.path.insert(0, WORKING_DIR)\n",
        "else:\n",
        "    # The actual code is one level higher in folder depth/structure, so we're elevating this notebook.\n",
        "    sys.path.insert(0,f\"{WORKING_DIR}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nnvr8_-Shbc",
        "outputId": "a9bb11dd-ed8a-4ae0-d3a5-d8f3dad1ae74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V\n"
          ]
        }
      ],
      "source": [
        "# # %cd drive/MyDrive/Colab\\ Notebooks/Supervised\\ Learning/T2V\n",
        "# %cd /content/drive/MyDrive/Colab\\ Notebooks/Supervised\\ Learning/T2V\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1412IyZUKUJ"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GdqePw3Shbc"
      },
      "source": [
        "### Install Main Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dXCcdb_-8ej-",
        "outputId": "48cf320f-1c95-46d0-9181-8bec01d057e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Text-To-Video-Finetuning' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 5))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-cqx8d21z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-cqx8d21z\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit 79df50388df09d9615e3c067695a453bb0a694c0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/cloneofsimo/lora.git (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/cloneofsimo/lora.git to /tmp/pip-req-build-ani_pj5y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cloneofsimo/lora.git /tmp/pip-req-build-ani_pj5y\n",
            "  Resolved https://github.com/cloneofsimo/lora.git to commit bdd51b04c49fa90a88919a19850ec3b4cf3c5ecd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/microsoft/LoRA (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/microsoft/LoRA to /tmp/pip-req-build-rsf6v6h0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/LoRA /tmp/pip-req-build-rsf6v6h0\n",
            "  Resolved https://github.com/microsoft/LoRA to commit 4c0333854cb905966f8cc4e9a74068c1e507c7b7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate==0.19 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.16.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.35.2)\n",
            "Collecting einops (from -r requirements.txt (line 9))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decord (from -r requirements.txt (line 10))\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.4.1)\n",
            "Collecting omegaconf (from -r requirements.txt (line 13))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (4.8.0.76)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.10.13)\n",
            "Collecting compel (from -r requirements.txt (line 16))\n",
            "  Downloading compel-2.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.19->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0->-r requirements.txt (line 5)) (7.0.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0->-r requirements.txt (line 5)) (0.20.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.26.0.dev0->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.11.4)\n",
            "Collecting ftfy (from lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mediapipe (from lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 8)) (0.15.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 13))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing~=3.0 in /usr/local/lib/python3.10/dist-packages (from compel->-r requirements.txt (line 16)) (3.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (0.2.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.26.0.dev0->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 3)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->lora-diffusion==0.1.7->-r requirements.txt (line 6)) (2.21)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->lora-diffusion==0.1.7->-r requirements.txt (line 6))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: diffusers, lora-diffusion, loralib, antlr4-python3-runtime, fire\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.26.0.dev0-py3-none-any.whl size=1851214 sha256=07140db15ac45a51fb1643eb6e5a2ea6a0209d3413a60e5f8092df2fbcd38759\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bavpk5xw/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "  Building wheel for lora-diffusion (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lora-diffusion: filename=lora_diffusion-0.1.7-py3-none-any.whl size=37978 sha256=25dbd68675f2c7a4edcb4b237154a867b58ccf30720f6ef624a6197c6b45154c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bavpk5xw/wheels/66/ff/e9/63a74dd5353f22e07baad2e2c9be124e339c476767770d4020\n",
            "  Building wheel for loralib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for loralib: filename=loralib-0.1.2-py3-none-any.whl size=10151 sha256=2fdf0e10228e472efd194d2fb3fee6381c2ccd8d9e6b116b47596d4b87d24190\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bavpk5xw/wheels/c3/6a/c5/ff1095b30b45b70dbf92ee0ddd1a1c8612cfe6e1c4296b770b\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d14cba90bd6016f9c27caa21f659146bd2ab6e7ba49fecc0e156591cb8f51662\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=9acc96a54a4b70476b6c975fe197f4970204f3b47ad128b02e1b2aa414df1923\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built diffusers lora-diffusion loralib antlr4-python3-runtime fire\n",
            "Installing collected packages: antlr4-python3-runtime, smmap, setproctitle, sentry-sdk, omegaconf, loralib, ftfy, fire, einops, docker-pycreds, decord, sounddevice, gitdb, mediapipe, GitPython, diffusers, accelerate, wandb, lora-diffusion, compel\n",
            "Successfully installed GitPython-3.1.41 accelerate-0.19.0 antlr4-python3-runtime-4.9.3 compel-2.0.2 decord-0.6.0 diffusers-0.26.0.dev0 docker-pycreds-0.4.0 einops-0.7.0 fire-0.5.0 ftfy-6.1.3 gitdb-4.0.11 lora-diffusion-0.1.7 loralib-0.1.2 mediapipe-0.10.9 omegaconf-2.3.0 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 sounddevice-0.4.6 wandb-0.16.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.13.1)\n",
            "Requirement already satisfied: compel in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: diffusers>=0.11 in /usr/local/lib/python3.10/dist-packages (from compel) (0.26.0.dev0)\n",
            "Requirement already satisfied: pyparsing~=3.0 in /usr/local/lib/python3.10/dist-packages (from compel) (3.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from compel) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers~=4.25 in /usr/local/lib/python3.10/dist-packages (from compel) (4.35.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (0.20.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.11->compel) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.25->compel) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.25->compel) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.25->compel) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.25->compel) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->compel) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->compel) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->compel) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->compel) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->compel) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->compel) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers>=0.11->compel) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->compel) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.11->compel) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.11->compel) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.11->compel) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers>=0.11->compel) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->compel) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/ExponentialML/Text-To-Video-Finetuning.git\n",
        "%cd Text-To-Video-Finetuning/\n",
        "!pip install -r requirements.txt\n",
        "!pip install triton\n",
        "!pip install compel\n",
        "#!pip install xformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkZn2d3-UbFM"
      },
      "source": [
        "### Install Main Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5cN5AOw_Yf3",
        "outputId": "debd8a8f-6cc9-481b-f642-a2ae63b8dedb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Git LFS initialized.\n",
            "Cloning into 'text-to-video-ms-1.7b'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 79 (delta 32), reused 75 (delta 30), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (79/79), 523.89 KiB | 1.89 MiB/s, done.\n",
            "Filtering content: 100% (12/12), 12.51 GiB | 32.65 MiB/s, done.\n",
            "Encountered 2 file(s) that may not have been copied correctly on Windows:\n",
            "\tunet/diffusion_pytorch_model.safetensors\n",
            "\tunet/diffusion_pytorch_model.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "# %cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/\n",
        "%cd WORKING_DIR\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/damo-vilab/text-to-video-ms-1.7b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLcaDPTfUfjp"
      },
      "source": [
        "### Install BLIP2 Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHIb40IV_wwW",
        "outputId": "de8c62cf-35f5-4df0-9a09-c7701d59f643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning\n",
            "fatal: destination path 'Video-BLIP2-Preprocessor' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor\n",
            "Collecting git+https://github.com/huggingface/transformers (from -r requirements.txt (line 6))\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-sk6ebo9f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-sk6ebo9f\n",
            "  Resolved https://github.com/huggingface/transformers to commit bc72b4e2cdcbc80d5f56731f35dbc9c18b4c8de6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.6.0)\n",
            "Collecting av (from -r requirements.txt (line 7))\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (0.20.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0->-r requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8338081 sha256=6e85fb4083a64d4ab2e51d693912334c694bd544a6d2e4d48c13b43c79c6d994\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m8l3n16d/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: av, transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed av-11.0.0 transformers-4.37.0.dev0\n"
          ]
        }
      ],
      "source": [
        "%cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/\n",
        "!git clone https://github.com/ExponentialML/Video-BLIP2-Preprocessor.git\n",
        "%cd Video-BLIP2-Preprocessor/\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awu5Sjm7LFqc"
      },
      "source": [
        "## Preprocess Videos\n",
        "See arguments you can pass [here](https://github.com/ExponentialML/Video-BLIP2-Preprocessor#default-arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xdxr3cP7hvvo"
      },
      "outputs": [],
      "source": [
        "# %cd {WORKING_DIR}/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor\n",
        "# !python preprocess.py --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4nj1I9pShbf",
        "outputId": "762bfc83-4521-403b-c835-0ef35ee68a5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "making directory\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+7)(x-7) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+7)(x-7) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+4)(x-4) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+4)(x-4) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+3)(x-3) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+3)(x-3) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+1)(x-1) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+1)(x-1) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+6)(x-6) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+6)(x-6) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+9)(x-9) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+9)(x-9) explained.mp4\n",
            "1\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+9)(x-9) explained b.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+9)(x-9) explained b.mp4\n",
            "1\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+5)(x-5) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+5)(x-5) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+2)(x-2) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+2)(x-2) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+8)(x-8) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+8)(x-8) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4/Simplify (x+10)(x-10) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+10)(x-10) explained.mp4\n",
            "0\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/test/(x+10)(x-10)/Simplify (x+10)(x-10) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+10)(x-10) explained.mp4\n",
            "12\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+3)(x-3)/Simplify (x+3)(x-3) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+3)(x-3) explained.mp4\n",
            "13\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+4)(x-4)/Simplify (x+4)(x-4) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+4)(x-4) explained.mp4\n",
            "25\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+7)(x-7)/Simplify (x+7)(x-7) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+7)(x-7) explained.mp4\n",
            "13\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+8)(x-8)/Simplify (x+8)(x-8) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+8)(x-8) explained.mp4\n",
            "12\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+2)(x-2)/Simplify (x+2)(x-2) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+2)(x-2) explained.mp4\n",
            "25\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+5)(x-5)/Simplify (x+5)(x-5) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+5)(x-5) explained.mp4\n",
            "12\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+6)(x-6)/Simplify (x+6)(x-6) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+6)(x-6) explained.mp4\n",
            "13\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+9)(x-9)/Simplify (x+9)(x-9) explained b.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+9)(x-9) explained b.mp4\n",
            "12\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+9)(x-9)/Simplify (x+9)(x-9) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+9)(x-9) explained.mp4\n",
            "12\n",
            "/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/train/(x+1)(x-1)/Simplify (x+1)(x-1) explained.mp4\n",
            "output_path /content/train_all_mp4/Simplify (x+1)(x-1) explained.mp4\n",
            "26\n",
            "Simplify (x+1)(x-1) explained.mp4 Simplify (x+1)(x-1) explained.mp4\n",
            "Simplify (x+2)(x-2) explained.mp4 Simplify (x+2)(x-2) explained.mp4\n",
            "Simplify (x+3)(x-3) explained.mp4 Simplify (x+3)(x-3) explained.mp4\n",
            "Simplify (x+4)(x-4) explained.mp4 Simplify (x+4)(x-4) explained.mp4\n",
            "Simplify (x+5)(x-5) explained.mp4 Simplify (x+5)(x-5) explained.mp4\n",
            "Simplify (x+6)(x-6) explained.mp4 Simplify (x+6)(x-6) explained.mp4\n",
            "Simplify (x+7)(x-7) explained.mp4 Simplify (x+7)(x-7) explained.mp4\n",
            "Simplify (x+8)(x-8) explained.mp4 Simplify (x+8)(x-8) explained.mp4\n",
            "Simplify (x+9)(x-9) explained.mp4 Simplify (x+9)(x-9) explained.mp4\n",
            "x^2+3x+2/x^2+3x+2 a.mov x^2+3x+2\n",
            "x^2+4x+3/x^2+4x+3 a.mov x^2+4x+3\n",
            "x^2+6x+5/x^2+6x+5 a.mov x^2+6x+5\n",
            "x^2+8x+7/x^2+8x+7 a.mov x^2+8x+7\n",
            "x^2+9x+8/x^2+9x+8 a.mov x^2+9x+8\n",
            "x^2+10x+9/x^2+10x+9 a.mov x^2+10x+9\n",
            "x^2+11x+10/x^2+11x+10 a.mov x^2+11x+10\n",
            "x^2+12x+11/x^2+12x+11 a.mov x^2+12x+11\n",
            "x^2+13x+12/x^2+13x+12 a.mov x^2+13x+12\n",
            "x^2+14x+13/x^2+14x+13 a.mov x^2+14x+13\n",
            "x^2+15x+14/x^2+15x+14 a.mov x^2+15x+14\n",
            "x^2+16x+15/x^2+16x+15 a.mov x^2+16x+15\n",
            "x^2+17x+16/x^2+17x+16 a.mov x^2+17x+16\n",
            "x^2+19x+18/x^2+19x+18 a.mov x^2+19x+18\n",
            "x^2+20x+19/x^2+20x+19 a.mov x^2+20x+19\n",
            "x^2+21x+20/x^2+21x+20 a.mov x^2+21x+20\n",
            "x^2+25x+24/x^2+25x+24 a.mov x^2+25x+24\n",
            "x^2+26x+25/x^2+26x+25 a.mov x^2+26x+25\n",
            "x^2+27x+26/x^2+27x+26 a.mov x^2+27x+26\n",
            "x^2+28x+27/x^2+28x+27 a.mov x^2+28x+27\n",
            "x^2+29x+28/x^2+29x+28 a.mov x^2+29x+28\n",
            "x^2+31x+30/x^2+31x+30 a.mov x^2+31x+30\n",
            "x^2+32x+31/x^2+32x+31 a.mov x^2+32x+31\n",
            "x^2+33x+32/x^2+33x+32 a.mov x^2+33x+32\n",
            "x^2+34x+33/x^2+34x+33 a.mov x^2+34x+33\n",
            "x^2+35x+34/x^2+35x+34 a.mov x^2+35x+34\n",
            "x^2+36x+35/x^2+36x+35 a.mov x^2+36x+35\n",
            "x^2+37x+36/x^2+37x+36 a.mov x^2+37x+36\n",
            "Simplify (x+10)(x-10) explained.mp4 Simplify (x+10)(x-10) explained.mp4\n",
            "x^2+100x+99/x^2+100x+99 a.mov x^2+100x+99\n",
            "x^2+101x+100/x^2+101x+100 a.mov x^2+101x+100\n"
          ]
        }
      ],
      "source": [
        "# from utils.skip_frames import generate_text_files, process_videos\n",
        "\n",
        "\n",
        "#input dir is folder of images and json is the json for anntoations corresponding to the images in appimate data folder\n",
        "input_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Appimate'\n",
        "json_file_path = '/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/dataset.json'\n",
        "# output_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/Appimate/T2V/train_all_mp4'\n",
        "output_dir = '/content/train_all_mp4'\n",
        "n = 1\n",
        "skip_interval = n  # skip every n frames\n",
        "\n",
        "process_videos(input_dir, output_dir, skip_interval)\n",
        "generate_text_files(output_dir, json_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFdu2IK6BZcj",
        "outputId": "11ece480-8cab-43c9-e691-c9e052ceeb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor\n",
            "Loading BLIP2\n",
            "2024-01-14 08:59:34.890291: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-14 08:59:34.890342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-14 08:59:34.891876: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-14 08:59:35.998196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 2/2 [00:03<00:00,  1.67s/it]\n",
            "Processing videos in /content/train_all_mp4: 0it [00:00, ?it/s]\n",
            "Processing Simplify (x+8)(x-8) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+8)(x-8) explained.mp4:  50% 1/2 [00:01<00:01,  1.52s/it]\u001b[A\n",
            "Processing Simplify (x+8)(x-8) explained.mp4: 100% 2/2 [00:02<00:00,  1.08s/it]\n",
            "\n",
            "Processing Simplify (x+3)(x-3) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+3)(x-3) explained.mp4:  50% 1/2 [00:00<00:00,  1.97it/s]\u001b[A\n",
            "Processing Simplify (x+3)(x-3) explained.mp4: 100% 2/2 [00:01<00:00,  1.73it/s]\n",
            "\n",
            "Processing Simplify (x+7)(x-7) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+7)(x-7) explained.mp4:  50% 1/2 [00:00<00:00,  1.26it/s]\u001b[A\n",
            "Processing Simplify (x+7)(x-7) explained.mp4: 100% 2/2 [00:01<00:00,  1.25it/s]\n",
            "\n",
            "Processing Simplify (x+10)(x-10) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+10)(x-10) explained.mp4:  50% 1/2 [00:00<00:00,  1.37it/s]\u001b[A\n",
            "Processing Simplify (x+10)(x-10) explained.mp4: 100% 2/2 [00:01<00:00,  1.32it/s]\n",
            "\n",
            "Processing Simplify (x+2)(x-2) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+2)(x-2) explained.mp4:  50% 1/2 [00:00<00:00,  1.29it/s]\u001b[A\n",
            "Processing Simplify (x+2)(x-2) explained.mp4: 100% 2/2 [00:01<00:00,  1.35it/s]\n",
            "\n",
            "Processing Simplify (x+4)(x-4) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+4)(x-4) explained.mp4:  50% 1/2 [00:00<00:00,  1.77it/s]\u001b[A\n",
            "Processing Simplify (x+4)(x-4) explained.mp4: 100% 2/2 [00:01<00:00,  1.58it/s]\n",
            "\n",
            "Processing Simplify (x+1)(x-1) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+1)(x-1) explained.mp4:  50% 1/2 [00:00<00:00,  1.85it/s]\u001b[A\n",
            "Processing Simplify (x+1)(x-1) explained.mp4: 100% 2/2 [00:01<00:00,  1.85it/s]\n",
            "\n",
            "Processing Simplify (x+9)(x-9) explained b.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+9)(x-9) explained b.mp4:  50% 1/2 [00:00<00:00,  1.89it/s]\u001b[A\n",
            "Processing Simplify (x+9)(x-9) explained b.mp4: 100% 2/2 [00:01<00:00,  1.54it/s]\n",
            "\n",
            "Processing Simplify (x+5)(x-5) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+5)(x-5) explained.mp4:  50% 1/2 [00:00<00:00,  1.26it/s]\u001b[A\n",
            "Processing Simplify (x+5)(x-5) explained.mp4: 100% 2/2 [00:01<00:00,  1.45it/s]\n",
            "\n",
            "Processing Simplify (x+9)(x-9) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+9)(x-9) explained.mp4:  50% 1/2 [00:00<00:00,  1.86it/s]\u001b[A\n",
            "Processing Simplify (x+9)(x-9) explained.mp4: 100% 2/2 [00:01<00:00,  1.50it/s]\n",
            "\n",
            "Processing Simplify (x+6)(x-6) explained.mp4:   0% 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Simplify (x+6)(x-6) explained.mp4:  50% 1/2 [00:00<00:00,  1.24it/s]\u001b[A\n",
            "Processing Simplify (x+6)(x-6) explained.mp4: 100% 2/2 [00:01<00:00,  1.25it/s]\n",
            "Processing videos in /content/train_all_mp4: 1it [00:15, 15.93s/it]\n",
            "Done. Saving train config to /content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor/train_data.\n"
          ]
        }
      ],
      "source": [
        "dataDir = \"/content/drive/MyDrive/Colab\\ Notebooks/datasets\"\n",
        "%cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor\n",
        "!python preprocess.py \\\n",
        "--video_directory {WORKING_DIR}/train_all_mp4 \\\n",
        "--config_name \"secrets\" \\\n",
        "--config_save_name \"secrets\" \\\n",
        "--prompt_amount 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4dk_Mnajp4"
      },
      "source": [
        "## Train Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD57bRlYShbf",
        "outputId": "7f93ac37-d141-4f4b-f22d-2211ce7d457e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning\n"
          ]
        }
      ],
      "source": [
        "%cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAgtbwp1WTwd"
      },
      "outputs": [],
      "source": [
        "# pretrained_model_path: \"/content/drive/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/text-to-video-ms-1.7b\" #https://huggingface.co/damo-vilab/text-to-video-ms-1.7b/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKG_b7qua7SX",
        "outputId": "7ab65872-74b7-4a37-8b35-8817ba3802be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting ./configs/my_config_hq.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile ./configs/my_config_hq.yaml\n",
        "\n",
        "pretrained_model_path: \"/content/text-to-video-ms-1.7b\" #https://huggingface.co/damo-vilab/text-to-video-ms-1.7b/tree/main\n",
        "output_dir: \"/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/outputs\"\n",
        "train_text_encoder: False\n",
        "#resume_from_checkpoint: None\n",
        "dataset_types:\n",
        "  - 'folder'\n",
        "\n",
        "train_data:\n",
        "  # #single_video_path: \"/home/gaurav/Text-to-Video/Appimate/videos/video1.mp4\"\n",
        "  # path: \"/home/gaurav/Text-to-Video/AutoVisual/train_all_mp4\"\n",
        "  path: \"/content/train_all_mp4\"\n",
        "  #json_path: \"/home/gaurav/Text-to-Video/AutoVisual/Text-To-Video-Finetuning/Video-BLIP2-Preprocessor/train_data/secrets.json\"\n",
        "  preprocessed: True\n",
        "  n_sample_frames: 2\n",
        "  shuffle_frames: False\n",
        "  width: 384\n",
        "  height: 256\n",
        "  sample_start_idx: 0\n",
        "  sample_frame_rate: 24\n",
        "  vid_data_key: \"video_path\"\n",
        "\n",
        "  # single_video_path: \"\"\n",
        "  single_video_prompt: \"\"\n",
        "\n",
        "validation_data:\n",
        "  prompt: \"\"\n",
        "  sample_preview: True\n",
        "  num_frames: 16\n",
        "  width: 384\n",
        "  height: 256\n",
        "  num_inference_steps: 50\n",
        "  guidance_scale: 9\n",
        "\n",
        "learning_rate: 1e-5\n",
        "adam_weight_decay: 1e-2\n",
        "train_batch_size: 1\n",
        "max_train_steps: 15000\n",
        "checkpointing_steps: 2500\n",
        "validation_steps: 2500\n",
        "trainable_modules:\n",
        "  - \"attentions\"\n",
        "seed: 64\n",
        "mixed_precision: \"fp16\"\n",
        "use_8bit_adam: False # This seems to be incompatible at the moment.\n",
        "\n",
        "gradient_checkpointing: True\n",
        "text_encoder_gradient_checkpointing: True\n",
        "# Xformers must be installed\n",
        "enable_xformers_memory_efficient_attention: False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDi0xUClURbC",
        "outputId": "dd411091-ecd2-4ea8-9e2e-f5e03d07dca2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX1eFvYTLldG",
        "outputId": "c827cf29-a327-410d-cc66-0741fbc7047c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-14 09:01:07.627385: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-14 09:01:07.627438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-14 09:01:07.629019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-14 09:01:08.733269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing the conversion map\n",
            "01/14/2024 09:01:18 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:244: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
            "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "{'variance_type', 'timestep_spacing', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "{'force_upcast'} was not found in config. Values will be initialized to default values.\n",
            "{'downsample_padding', 'mid_block_scale_factor'} was not found in config. Values will be initialized to default values.\n",
            "train_data {'path': '/content/train_all_mp4', 'preprocessed': True, 'n_sample_frames': 2, 'shuffle_frames': False, 'width': 384, 'height': 256, 'sample_start_idx': 0, 'sample_frame_rate': 24, 'vid_data_key': 'video_path', 'single_video_prompt': ''}\n",
            "dataset_types ['folder']\n",
            "json\n",
            "dataset_types ['folder']\n",
            "single_video\n",
            "dataset_types ['folder']\n",
            "image\n",
            "dataset_types ['folder']\n",
            "folder\n",
            "dataset type folder\n",
            "--------------------- 1\n",
            "text_enable True\n",
            "01/14/2024 09:01:33 - INFO - __main__ - ***** Running training *****\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Num examples = 11\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Num Epochs = 1364\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "01/14/2024 09:01:33 - INFO - __main__ -   Total optimization steps = 15000\n",
            "Steps:   0% 0/15000 [00:00<?, ?it/s]832 params have been processed.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n",
            "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/configuration_utils.py:139: FutureWarning: Accessing config attribute `prediction_type` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'prediction_type' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.prediction_type'.\n",
            "  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "Steps:   0% 1/15000 [00:03<15:54:13,  3.82s/it]Performing validation prompt.\n",
            "text_enable False\n",
            "\n",
            "Loading pipeline components...:   0% 0/5 [00:00<?, ?it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of /content/text-to-video-ms-1.7b.\n",
            "{'timestep_spacing', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as DDIMScheduler from `scheduler` subfolder of /content/text-to-video-ms-1.7b.\n",
            "Loading pipeline components...: 100% 5/5 [00:00<00:00, 67.57it/s]\n",
            "{'algorithm_type', 'euler_at_final', 'lambda_min_clipped', 'solver_type', 'use_karras_sigmas', 'timestep_spacing', 'variance_type', 'use_lu_lambdas', 'lower_order_final', 'solver_order'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "  0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 1/50 [00:00<00:16,  2.99it/s]\u001b[A\n",
            "  4% 2/50 [00:00<00:10,  4.61it/s]\u001b[A\n",
            "  6% 3/50 [00:00<00:10,  4.67it/s]\u001b[A\n",
            "  8% 4/50 [00:00<00:09,  4.70it/s]\u001b[A\n",
            " 10% 5/50 [00:01<00:09,  4.71it/s]\u001b[A\n",
            " 12% 6/50 [00:01<00:09,  4.72it/s]\u001b[A\n",
            " 14% 7/50 [00:01<00:09,  4.72it/s]\u001b[A\n",
            " 16% 8/50 [00:01<00:08,  4.73it/s]\u001b[A\n",
            " 18% 9/50 [00:01<00:08,  4.73it/s]\u001b[A\n",
            " 20% 10/50 [00:02<00:08,  4.73it/s]\u001b[A\n",
            " 22% 11/50 [00:02<00:08,  4.74it/s]\u001b[A\n",
            " 24% 12/50 [00:02<00:08,  4.74it/s]\u001b[A\n",
            " 26% 13/50 [00:02<00:07,  4.74it/s]\u001b[A\n",
            " 28% 14/50 [00:03<00:07,  4.74it/s]\u001b[A\n",
            " 30% 15/50 [00:03<00:07,  4.74it/s]\u001b[A\n",
            " 32% 16/50 [00:03<00:07,  4.74it/s]\u001b[A\n",
            " 34% 17/50 [00:03<00:06,  4.74it/s]\u001b[A\n",
            " 36% 18/50 [00:03<00:06,  4.74it/s]\u001b[A\n",
            " 38% 19/50 [00:04<00:06,  4.74it/s]\u001b[A\n",
            " 40% 20/50 [00:04<00:06,  4.74it/s]\u001b[A\n",
            " 42% 21/50 [00:04<00:06,  4.74it/s]\u001b[A\n",
            " 44% 22/50 [00:04<00:05,  4.74it/s]\u001b[A\n",
            " 46% 23/50 [00:04<00:05,  4.74it/s]\u001b[A\n",
            " 48% 24/50 [00:05<00:05,  4.74it/s]\u001b[A\n",
            " 50% 25/50 [00:05<00:05,  4.74it/s]\u001b[A\n",
            " 52% 26/50 [00:05<00:05,  4.74it/s]\u001b[A\n",
            " 54% 27/50 [00:05<00:04,  4.74it/s]\u001b[A\n",
            " 56% 28/50 [00:05<00:04,  4.74it/s]\u001b[A\n",
            " 58% 29/50 [00:06<00:04,  4.74it/s]\u001b[A\n",
            " 60% 30/50 [00:06<00:04,  4.74it/s]\u001b[A\n",
            " 62% 31/50 [00:06<00:04,  4.74it/s]\u001b[A\n",
            " 64% 32/50 [00:06<00:03,  4.74it/s]\u001b[A\n",
            " 66% 33/50 [00:07<00:03,  4.74it/s]\u001b[A\n",
            " 68% 34/50 [00:07<00:03,  4.74it/s]\u001b[A\n",
            " 70% 35/50 [00:07<00:03,  4.74it/s]\u001b[A\n",
            " 72% 36/50 [00:07<00:02,  4.74it/s]\u001b[A\n",
            " 74% 37/50 [00:07<00:02,  4.74it/s]\u001b[A\n",
            " 76% 38/50 [00:08<00:02,  4.74it/s]\u001b[A\n",
            " 78% 39/50 [00:08<00:02,  4.74it/s]\u001b[A\n",
            " 80% 40/50 [00:08<00:02,  4.74it/s]\u001b[A\n",
            " 82% 41/50 [00:08<00:01,  4.74it/s]\u001b[A\n",
            " 84% 42/50 [00:08<00:01,  4.74it/s]\u001b[A\n",
            " 86% 43/50 [00:09<00:01,  4.74it/s]\u001b[A\n",
            " 88% 44/50 [00:09<00:01,  4.74it/s]\u001b[A\n",
            " 90% 45/50 [00:09<00:01,  4.74it/s]\u001b[A\n",
            " 92% 46/50 [00:09<00:00,  4.74it/s]\u001b[A\n",
            " 94% 47/50 [00:09<00:00,  4.74it/s]\u001b[A\n",
            " 96% 48/50 [00:10<00:00,  4.73it/s]\u001b[A\n",
            " 98% 49/50 [00:10<00:00,  4.73it/s]\u001b[A\n",
            "100% 50/50 [00:10<00:00,  4.72it/s]\n",
            "01/14/2024 09:01:48 - INFO - __main__ - Saved a new sample to /content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/outputs/train_2024-01-14T09-01-18/samples/1_dataset-['folder']_.mp4\n",
            "text_enable True\n",
            "Steps:   0% 1/15000 [00:15<15:54:13,  3.82s/it, lr=1e-5, step_loss=0.76]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "Steps:   0% 33/15000 [00:55<5:08:54,  1.24s/it, lr=1e-5, step_loss=0.0286]"
          ]
        }
      ],
      "source": [
        "# %cd ./Text-To-Video-Finetuning\n",
        "# %cd {WORKING_DIR}/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/\n",
        "!python train.py --config ./configs/my_config_hq.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep3Z-VIDfW6d",
        "outputId": "18e334d1-4f07-4296-b5bd-bff3d0f47c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: diffusers\n",
            "Version: 0.26.0.dev0\n",
            "Summary: State-of-the-art diffusion in PyTorch and JAX.\n",
            "Home-page: https://github.com/huggingface/diffusers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/diffusers/graphs/contributors)\n",
            "Author-email: patrick@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, importlib-metadata, numpy, Pillow, regex, requests, safetensors\n",
            "Required-by: compel, lora-diffusion\n"
          ]
        }
      ],
      "source": [
        "!pip show diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLjl03Roi-QU",
        "outputId": "74414dae-dee3-4612-e1a7-2255d0c33a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting diffusers==0.20.2\n",
            "  Downloading diffusers-0.20.2.tar.gz (989 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/989.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/989.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/989.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.1/989.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (0.20.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (1.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (0.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.20.2) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.20.2) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.20.2) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.20.2) (2023.11.17)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.20.2-py3-none-any.whl size=1342632 sha256=678ec36dda41d970de07b909b40c93679d2ca958294a8cf7c772c7001fe15c5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/8b/d9/34f7a1936109e05e9bba0cc2241a6f8cd89e25959dc7aae942\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.26.0.dev0\n",
            "    Uninstalling diffusers-0.26.0.dev0:\n",
            "      Successfully uninstalled diffusers-0.26.0.dev0\n",
            "Successfully installed diffusers-0.20.2\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers==0.20.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEuPRfNcjL2p",
        "outputId": "758d7903-57ff-414b-e0c1-ef0c90c11e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: diffusers\n",
            "Version: 0.20.2\n",
            "Summary: Diffusers\n",
            "Home-page: https://github.com/huggingface/diffusers\n",
            "Author: The HuggingFace team\n",
            "Author-email: patrick@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, importlib-metadata, numpy, Pillow, regex, requests, safetensors\n",
            "Required-by: compel, lora-diffusion\n"
          ]
        }
      ],
      "source": [
        "!pip show diffusers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RbttjgDShbf"
      },
      "source": [
        "### Freeze Environment Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yAPyZ_2nSXps"
      },
      "outputs": [],
      "source": [
        "# !pip freeze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DotzCfQbShbf"
      },
      "source": [
        "# Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6iy3bIOhfgE",
        "outputId": "4296fae8-b85a-49e9-8198-27c29cf81f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-13 20:39:26.638149: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-13 20:39:26.638204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-13 20:39:26.640846: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-13 20:39:27.806073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Initializing the conversion map\n",
            "Loading pipeline components...: 100% 5/5 [00:00<00:00, 9915.61it/s]\n",
            "33 Attention layers using Scaled Dot Product Attention.\n",
            "Diffusing timestep 39...: : 50it [00:07,  6.85it/s]\n",
            "Decoding to pixels...: 100% 16/16 [00:00<00:00, 45.11frame/s]\n"
          ]
        }
      ],
      "source": [
        "!python inference.py --model \"/content/drive/MyDrive/Colab Notebooks/Supervised Learning/T2V/Text-To-Video-Finetuning/outputs/train_2024-01-13T20-29-09/checkpoint-50\" --prompt \"Simplify (x+1)(x-1) explained\" --num-frames 16 --window-size 12 --width 384 --height 256 --sdp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1DttecwShbf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from diffusers import DPMSolverMultistepScheduler, DDPMScheduler, TextToVideoSDPipeline\n",
        "from diffusers.utils import export_to_video\n",
        "from compel import Compel\n",
        "import imageio\n",
        "\n",
        "def to_video(fn: str, frames: list[np.ndarray], fps: int) -> str:\n",
        "    # out_file = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)\n",
        "    writer = imageio.get_writer(fn, format='FFMPEG', fps=fps)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    return fn\n",
        "\n",
        "# my_trained_model_path = f\"{WORKING_DIR}/Text-To-Video-Finetuning/outputs/train_2023-12-06T21-23-48/checkpoint-12500\"\n",
        "# pipe = TextToVideoSDPipeline.from_pretrained(my_trained_model_path,torch_dtype=torch.float16, variant=\"fp16\")\n",
        "# compel = Compel(tokenizer=pipe.tokenizer, text_encoder=pipe.text_encoder)\n",
        "# pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "# pipe.enable_model_cpu_offload()\n",
        "\n",
        "\n",
        "# seed = random.randint(0, 1000000)\n",
        "# generator = torch.Generator().manual_seed(seed)\n",
        "\n",
        "# prompt = \"(x+1)(x-1) expression simplified\"\n",
        "# neg_prompt = \"watermark+++, text, shutterstock text, shutterstock++, blurry, ugly, username, url, low resolution, low quality\"\n",
        "# prompt_embeds = compel.build_conditioning_tensor(prompt)\n",
        "# neg_prompt_embeds = compel.build_conditioning_tensor(neg_prompt)\n",
        "# video_frames = pipe(prompt_embeds=prompt_embeds, negative_prompt_embeds=neg_prompt_embeds, num_frames=100, width=384, height=256, num_inference_steps=50, guidance_scale=9, generator=generator).frames\n",
        "\n",
        "# prompt_string = prompt.replace(\" \", \"-\")\n",
        "# out_file = f\"{WORKING_DIR}/\"+prompt_string+\"-seed\"+str(seed)+\".mp4\"\n",
        "# video_path = to_video(out_file, video_frames, 24)\n",
        "# #video_path = export_to_video(video_frames, out_file)\n",
        "# print(video_path+ \" is ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mb0SZgJUShbg",
        "outputId": "cffc7720-ef56-4125-e94a-00826570bce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pytorch-lightning==1.3.3\n",
            "torch==2.1.1\n",
            "torchaudio==2.1.1\n",
            "torchmetrics==0.3.2\n",
            "torchtext==0.8.1\n",
            "torchvision==0.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipW13ByAShbg",
        "outputId": "3daf3dc6-568e-4ad7-f988-5b62fd8ba982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "diffusers @ git+https://github.com/huggingface/diffusers.git@d486f0e84669447b178569ad499eeb86c739b99e\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep diffusers"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
